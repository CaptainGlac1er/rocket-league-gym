:py:mod:`rlgym.gym`
===================

.. py:module:: rlgym.gym

.. autoapi-nested-parse::

   The Rocket League gym environment.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   rlgym.gym.Gym




.. py:class:: Gym(match, pipe_id=0, launch_preference=LaunchPreference.EPIC, use_injector=False, force_paging=False, raise_on_crash=False, auto_minimize=False)

   Bases: :py:obj:`gym.Env`

   The main OpenAI Gym class.

   It encapsulates an environment with arbitrary behind-the-scenes dynamics.
   An environment can be partially or fully observed.

   The main API methods that users of this class need to know are:

   - :meth:`step` - Takes a step in the environment using an action returning the next observation, reward,
     if the environment terminated and observation information.
   - :meth:`reset` - Resets the environment to an initial state, returning the initial observation and observation information.
   - :meth:`render` - Renders the environment observation with modes depending on the output
   - :meth:`close` - Closes the environment, important for rendering where pygame is imported

   And set the following attributes:

   - :attr:`action_space` - The Space object corresponding to valid actions
   - :attr:`observation_space` - The Space object corresponding to valid observations
   - :attr:`reward_range` - A tuple corresponding to the minimum and maximum possible rewards
   - :attr:`spec` - An environment spec that contains the information used to initialise the environment from `gym.make`
   - :attr:`metadata` - The metadata of the environment, i.e. render modes
   - :attr:`np_random` - The random number generator for the environment

   Note: a default reward range set to :math:`(-\infty,+\infty)` already exists. Set it if you want a narrower range.

   .. py:method:: _open_game()


   .. py:method:: _setup_plugin_connection()


   .. py:method:: _page_client() -> bool


   .. py:method:: _minimize_game()


   .. py:method:: reset(return_info=False) -> Union[List, Tuple]

      The environment reset function. When called, this will reset the state of the environment and objects in the game.
      This should be called once when the environment is initialized, then every time the `done` flag from the `step()`
      function is `True`.


   .. py:method:: step(actions: Any) -> Tuple[List, List, bool, Dict]

      The step function will send the list of provided actions to the game, then advance the game forward by `tick_skip`
      physics ticks using that action. The game is then paused, and the current state is sent back to RLGym. This is
      decoded into a `GameState` object, which gets passed to the configuration objects to determine the rewards,
      next observation, and done signal.

      :param actions: An object containing actions, in the format specified by the `ActionParser`.
      :return: A tuple containing (obs, rewards, done, info)


   .. py:method:: close()

      Disconnect communication with the Bakkesmod plugin and close the game. This should only be called if you are finished
      with your current RLGym environment instance.


   .. py:method:: update_settings(game_speed=None, gravity=None, boost_consumption=None)

      Updates the specified RLGym instance settings

      :param game_speed: The speed the physics will run at, leave it at 100 unless your game can't run at over 240fps
      :param gravity:
      :param boost_consumption:


   .. py:method:: _receive_state()


   .. py:method:: _send_actions(actions)


   .. py:method:: _handle_exception()


   .. py:method:: attempt_recovery()



