:py:mod:`rlgym.utils.reward_functions.reward_function`
======================================================

.. py:module:: rlgym.utils.reward_functions.reward_function

.. autoapi-nested-parse::

   The reward function.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   rlgym.utils.reward_functions.reward_function.RewardFunction




.. py:class:: RewardFunction

   Bases: :py:obj:`abc.ABC`

   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:method:: reset(initial_state: rlgym.utils.gamestates.GameState)
      :abstractmethod:

      Function to be called each time the environment is reset. This is meant to enable users to design stateful reward
      functions that maintain information about the game throughout an episode to determine a reward.

      :param initial_state: The initial state of the reset environment.


   .. py:method:: pre_step(state: rlgym.utils.gamestates.GameState)

      Function to pre-compute values each step. This function is called only once each step, before get_reward is
      called for each player.

      :param state: The current state of the game.


   .. py:method:: get_reward(player: rlgym.utils.gamestates.PlayerData, state: rlgym.utils.gamestates.GameState, previous_action: numpy.ndarray) -> float
      :abstractmethod:

      Function to compute the reward for a player. This function is given a player argument, and it is expected that
      the reward returned by this function will be for that player.

      :param player: Player to compute the reward for.
      :param state: The current state of the game.
      :param previous_action: The action taken at the previous environment step.

      :return: A reward for the player provided.


   .. py:method:: get_final_reward(player: rlgym.utils.gamestates.PlayerData, state: rlgym.utils.gamestates.GameState, previous_action: numpy.ndarray) -> float

      Function to compute the reward for a player at the final step of an episode. This will be called only once, when
      it is determined that the current state is a terminal one. This may be useful for sparse reward signals that only
      produce a value at the final step of an environment. By default, the regular get_reward is used.

      :param player: Player to compute the reward for.
      :param state: The current state of the game.
      :param previous_action: The action taken at the previous environment step.

      :return: A reward for the player provided.



